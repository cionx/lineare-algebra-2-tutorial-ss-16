%\documentclass[a4paper,10pt]{article}
\documentclass[a4paper, 10pt, numbers=noenddot]{scrartcl}

\usepackage{../generalstyle}
\usepackage{specificstyle}

\title{Lösungen zu Aufgabe 1, Zettel 8}
\author{Jendrik Stelzner}
\date{\today}

\begin{document}
\maketitle



\section{Vorbereitung: Basiswechselmatrizen}


\begin{lemma}
  Es sei $A \in \Mat_n(\Kbb)$.
  Dann sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Die Matrix $A$ ist invertierbar mit $A^{-1} = A^*$.
    \item
      Es gilt $A A^* = I$.
    \item
      Es gilt $A^* A = I$.
    \item
      Die Spalten von $A$ sind eine Orthonormalbasis von $\Kbb^n$ (als Spaltenvektoren gesehen).
    \item
      Die Zeilen von $A$ sind eine Orthonormalbasis von $\Kbb^n$ (als Zeilenvektoren gesehen).
  \end{enumerate}
\end{lemma}
\begin{proof}
  Die Äquivalenz der ersten drei Aussagen folgt, wie aus Lineare Algebra I bekannt, mithilfe der Dimensionsformel.
  
  Die Gleichheit $A^* A = I$ ist in den Einträgen äquivalent dazu, dass $\sum_{l=1}^n \overline{a_{lj}} a_{lk} = \delta_{jk}$ für alle $j,k = 1, \dotsc, n$.
  Durch komplexe Konjugation ist dies äquivalent zu $\sum_{l=1}^n a_{lj} \overline{a_{lk}} = \delta_{j,k}$ für alle $j, k = 1, \dotsc, n$.
  Da der Ausdruck $\sum_{l=1}^n a_{lj} \overline{a_{lk}}$ das Standardskalarprodukt der $j$-ten und $k$-ten Spaltenvektoren von $A$ ist, bedeutet dies gerade, dass die Spalten von $A$ eine Orthonormalbasis von $\Kbb^n$ bilden.
  
  Analog ergibt sich, dass $A A^* = I$ äquivalent dazu ist, dass die Zeilen von $A$ eine Orthonormalbasis von $\Kbb^n$ bilden.
\end{proof}


Im Folgenen sei
\[
  D(\varphi)
  \coloneqq
  \begin{pmatrix*}[r]
    \cos \varphi  & -\sin \varphi \\
    \sin \varphi  &  \cos \varphi
  \end{pmatrix*}
\]
die Drehmatrix mit Winkel $\varphi \in \Rbb$.
Für Skalare $\lambda_1, \dotsc, \lambda_n \in \Cbb$ sei
\[
  \diag(\lambda_1, \dotsc, \lambda_n)
  \coloneqq
  \begin{pmatrix}
    \lambda_1 &         &           \\
              & \ddots  &           \\
              &         & \lambda_p
  \end{pmatrix}
  \in
  \Mat_n(\Cbb)
\]
die entsprechende Diagonalmatrix.
Für Matrizen $A_1 \in \Mat_{n_1}(\Cbb), \dotsc, A_r \in \Mat_{n_r}(\Cbb)$ sei
\[
  \block(A_1, \dotsc, A_r)
  =
  \begin{pmatrix}
    A_1 &         &     \\
        & \ddots  &     \\
        &         & A_r
  \end{pmatrix}
  \in
  \Mat_{n_1 + \dotsb + n_r}(\Cbb)
\]
die entsprechende Blockdiagonalmatrix.


\begin{theorem}\label{thrm: existence of unitary basis change matrix}
  \begin{enumerate}[leftmargin=*]
    \item
      Ist $A \in \Mat_n(\Cbb)$ normal, so gibt es eine unitäre Matrix $U \in \Unitary(n)$, so dass $U \! A U^{-1}$ in Diagonalgestalt ist.
      Die Diagonaleinträge sind dabei bis auf Permutation eindeutig bestimmt.
    \item
      Ist $A \in \Mat_n(\Cbb)$ selbstadjungiert, so gibt es eine unitäre Matrix $U \in \Unitary(n)$, so dass $U \! A U^{-1}$ in Diagonalgestalt mit reellen Diagonaleinträgen ist.
      Die Diagonaleinträge sind dabei bis auf Permutation eindeutig bestimmt.
    \item
      Ist $A \in \Mat_n(\Cbb)$ antiselbstadjungiert, so gibt es eine unitäre Matrix $U \in \Unitary(n)$, so dass $U \! A U^{-1}$ in Diagonalgestalt mit rein imaginären Diagonaleinträgen ist.
      Die Diagonaleinträge sind dabei bis auf Permutation eindeutig bestimmt.
    \item
      Ist $A \in \Mat_n(\Cbb)$ unitär, so gibt es eine unitäre Matrix $U \in \Unitary(n)$, so dass $U \! A U^{-1}$ in Diagonalgestalt ist, und alle Diagonaleinträge haben Betrag $1$.
      Die Diagonaleinträge sind dabei bis auf Permutation eindeutig bestimmt.
    \item
      Ist $A \in \Mat_n(\Rbb)$ normal, so gibt es eine orthogonale Matrix $O \in \Orthogonal(n)$, so dass
      \[
          O A O^{-1}
        = \block(\lambda_1, \dotsc, \lambda_p, r_1 D(\varphi_1), \dotsc, r_q D(\varphi_q)).
      \]
      mit $\lambda_1, \dotsc, \lambda_p \in \Rbb$, $r_1, \dotsc, r_q > 0$ und $\varphi_1, \dotsc, \varphi_q \in (0,\pi)$.
      Die Zahlen $p$ und $q$ sind dabei eindeutig bestimmt, und die Skalare $\lambda_1, \dotsc, \lambda_p \in \Rbb$ und Paare $(r_1, \varphi_1), \dotsc, (r_q, \varphi_q)$ sind jeweils bis auf Permutation eindeutig bestimmt.
    \item
      Ist $A \in \Mat_n(\Rbb)$ selbstadjungiert, so gibt es eine orthogonale Matrix $O \in \Orthogonal(n)$, so dass $O A O^{-1}$ in Diagonalgestalt ist.
      Die Diagonaleinträge sind dabei bis auf Permutation eindeutig bestimmt.
    \item
      Ist $A \in \Mat_n(\Rbb)$ orthogonal, so gibt es eine orthogonale Matrix $O \in \Orthogonal(n)$, so dass
      \[
          O A O^{-1}
        = \block(1, \dotsc, 1, -1, \dotsc, -1, D(\varphi_1), \dotsc, D(\varphi_r)).
      \]
      mit Winkeln $\varphi_1, \dotsc, \varphi_r \in (0,\pi)$.
      Dabei ist eindeutig bestimmt, wie häufig die Diagonaleinträge $1$ und $-1$ vorkommen, und die Winkel $\varphi_1, \dotsc, \varphi_n$ sind bis auf Permutation eindeutig bestimmt.
  \end{enumerate}
\end{theorem}


\begin{proof}
  Wir betrachten den Fall, dass $A \in \Mat_n(\Cbb)$ normal ist.
  Es sei $\mc{B} = (e_1, \dotsc, e_n)$ die Standardbasis von $\Cbb^n$ und $f \colon V \to V$ der eindeutige Endomorphismus mit $\Mat_{\mc{B}}(f) = A$.
  Da $\mc{B}$ eine Orthonormalbasis ist, folgt aus der Normalität von $A$, dass der Endomorphismus $f$ normal ist.
  Da $\Cbb^n$ endlichdimensional ist, gibt es eine Orthonormalbasis $\mc{C} = (c_1, \dotsc, c_n)$ von $\Cbb^n$ aus Eigenvektoren von $f$.
  Für die Basiswechselmatrix $U \coloneqq T^{\mc{B}}_{\mc{C}}$ gilt nun, dass
  \[
      U \! A U^{-1}
    = T^{\mc{B}}_{\mc{C}} \Mat_\mc{B}(f) T^{\mc{C}}_{\mc{B}}
    = \Mat_\mc{C}(f)
  \]
  eine Diagonalmatrix ist.
  Die Spalten der Matrix $U^{-1} = T^{\mc{C}}_\mc{B}$ sind genau die Spaltenvektoren $c_1, \dotsc, c_n \in \Cbb^n$.
  Also sind die Spalten von $U^{-1}$ eine Orthonormalbasis von $\Cbb^n$, und $U^{-1}$ ist somit unitär.
  Deshalb ist auch $U$ unitär.
  
  Das zeigt die erste Aussage.
  Die anderen Aussagen ergeben sich analog über die jeweilige Normalform der entsprechenden Endomorphismen.
\end{proof}


Im Folgenden seien $I, J \in \Mat_2(\Cbb)$ mit
\[
  I \coloneqq
  \begin{pmatrix}
    1 &   \\
      & 1
  \end{pmatrix}
  \quad\text{und}\quad
  J \coloneqq
  \begin{pmatrix}
      & -1  \\
    1 & 
  \end{pmatrix}.
\]


\begin{lemma}\label{lem: finding a logarithm for rotation matrices}
  Für alle $r, \theta \in \Rbb$ ist $r D(\theta) = \exp(\log(r) I + \theta J)$.
\end{lemma}
\begin{proof}
  Da $I$ und $J$ kommutieren (denn $I$ ist die Einheitsmatrix), kommutieren auch $\log(r) I$ und $\theta J$.
  Daher ist
  \[
      \exp(\log(r) I + \theta J)
    = \exp(\log(r) I) \exp(\theta J)
    = e^{\log(r)} I \exp(\theta J)
    = r \exp(\theta J).
  \]
  Aus $J^2 = -I$ ergibt sich für alle $n \in \Nbb$, dass
  \[
    J^n
    =
    \begin{cases}
      \phantom{-}I  & \text{falls $n \equiv 0 \pmod 4$},  \\
      \phantom{-}J  & \text{falls $n \equiv 1 \pmod 4$},  \\
                -I  & \text{falls $n \equiv 2 \pmod 4$},  \\
                -J  & \text{falls $n \equiv 3 \pmod 4$}.
    \end{cases}
  \]
  Damit ergibt sich, dass
  \begin{align*}
        \exp(\theta J)
    &=  \sum_{n=0}^\infty \frac{(\theta J)^n}{n!}
     =    \sum_{k=0}^\infty \frac{(\theta J)^{2k}}{(2k)!}
        + \sum_{k=0}^\infty \frac{(\theta J)^{2k+1}}{(2k+1)!}     \\
    &=    \sum_{k=0}^\infty (-1)^k \frac{\theta^{2k} I}{(2k)!}
        + \sum_{k=0}^\infty (-1)^k \frac{\theta^{2k+1} J}{(2k+1)!}
     =  \cos(\theta) I + \sin(\theta) J
     =  D(\theta).
  \end{align*}
  Zusammengefasst ist also $\exp(\log(r)I + \theta J) = r \exp(\theta J) = r D(\theta)$.
\end{proof}


\begin{remark}
  Lemma~\ref{lem: finding a logarithm for rotation matrices} lässt sich auch konzeptioneller begründen:
  Es sei
  \[
    C \coloneqq
    \left\{
      \begin{pmatrix*}[r]
        a & -b  \\
        b &  a
      \end{pmatrix*}
    \,\middle|\,
      a, b \in \Rbb
    \right\}
    \subseteq
    \Mat_2(\Rbb).
  \]
  Die Abbildung $\Phi \colon \Cbb \to C$ mit
  \[
    \Phi(a + i b)
    =
    \begin{pmatrix*}[r]
      a & -b  \\
      b &  a
    \end{pmatrix*}
    =
    a I + b J
    \quad
    \text{für alle $a, b \in \Rbb$}
  \]
  ist bijektiv, und durch direktes Nachrechnen ergibt sich, dass $\Phi$ bezüglich der üblichen Matrixaddition und -multiplikation ein Ringhomomorphismus ist. (D.h.\ für alle $z_1, z_2 \in \Cbb$ gilt $\Phi(z_1 + z_2) = \Phi(z_1) + \Phi(z_2)$, $\Phi(z_1 \cdot z_2) = \Phi(z_1) \cdot \Phi(z_2)$ und $\Phi(1) = I$.)
  Also ist $\Phi$ ein Ringisomorphismus.
  
  Da $\Cbb$ ein Körper ist, folgt damit, dass $C$ mit der üblichen Matrixaddition und -multi\-pli\-ka\-ti\-on ebenfalls ein Körper ist, und dass $\Phi$ ein Isomorphismus von Körpern ist.
  Dabei ist $\Phi(a + ib) = a I + b J$ für alle $a, b \in \Rbb$ und $\Phi(r e^{i\varphi}) = r D(\varphi)$ für alle $r \geq 0$ und $\varphi \in \Rbb$.
  
  Neben diesen algebraischen Eigenschaft sind $\Phi$ und $\Phi^{-1}$ auch stetig.
  Somit ist $\Phi$ auch ein Homöomorphismus.
  (Insgesamt ist $\Phi$ also ein Isomorphismus von topologischen Körpern.)
  
  Für alle $z_1, z_2 \in \Cbb$ ist deshalb genau dann $z_2 = \exp(z_1)$, wenn $\Phi(z_2) = \exp(\Phi(z_1))$.
  Somit lassen sich Aussagen über das Matrixexponential auf $C$ auf Aussagen über die Exponentialabbildung auf $\Cbb$ zurückführen.
  
  Inbesondere übersetzt sich das Problem, einen Logarithmus einer Matrix $r D(\varphi) \in C$ zu finden, dazu, einen Logarithmus einer komplexen Zahl $r e^{i \varphi}$ zu finden.
  Konkret ergibt sich aus $\exp(\log(r) + i \varphi) = r e^{i \varphi}$, dass
  \[
      r D(\varphi)
    = \Phi(r e^{i \varphi})
    = \Phi(\exp(\log(r) + i \varphi))
    = \exp(\Phi(\log(r) + i \varphi))
    = \exp(\log(r) I + \varphi J).
  \]
  
  Man bemerke, dass unter diesem Blickwinkel der obige Beweis von Lemma~\ref{lem: finding a logarithm for rotation matrices} eine Übersetzung des üblichen Beweises für $\exp(i \varphi) = \cos\varphi + i \sin \varphi$ ist.
\end{remark}


Der Vorteil an unitären (und damit auch orthogonalen) Basiswechselmatrizen besteht darin, dass sie mit dem Matrixadjungieren verträglich sind:


\begin{lemma}\label{lemma: unitary basis change matrices}
  Es sei $A \in \Mat_n(\Cbb)$ und $U \in \Unitary(n)$.
  Dann ist $(U \! A U^{-1})^* = U \! A^* U^{-1}$.
\end{lemma}
\begin{proof}
  Es ist
  $
      (U \! A U^{-1})^*
    = (U^{-1})^* A^* U^*
    = (U^*)^{-1} A^* U^*
    = (U^{-1})^{-1} A^* U^{-1}
    = U \! A U^{-1}.
  $
\end{proof}


\begin{corollary}\label{cor: properties and unitary basis change}
  Es sei $A \in \Mat_n(\Cbb)$ und $U \in \Unitary(n)$.
  \begin{enumerate}[leftmargin=*]
    \item
      Die Matrix $A$ ist genau dann normal, wenn $U \! A U^{-1}$ normal ist.
    \item
      Die Matrix $A$ ist genau dann selbstadjungiert, wenn $U \! A U^{-1}$ selbstadjungiert ist.
    \item
      Die Matrix $A$ ist genau dann antiselbstadjungiert, wenn $U \! A U^{-1}$ antiselbstadjungiert ist.
    \item
      Die Matrix $A$ ist genau dann unitär, wenn $U \! A U^{-1}$ unitär ist.
  \end{enumerate}
\end{corollary}


\begin{remark}
  Für nicht-unitäre Basiswechselmatrizen gilt zu zu Lemma~\ref{lemma: unitary basis change matrices} analoge Aussage nicht notwendigerweise.
  
  Allgemeiner gilt für $S \in \GL_n(\Cbb)$ genau dann $(S A S^{-1})^* = S A^* S^{-1}$ für alle $A \in \Mat_n(\Cbb)$, wenn $S = \lambda U$ für ein eine unitäre Matrix $U \in \Unitary(n)$ und einen invertierbaren Skalar $\lambda \in \Cbb^\times$.
  Durch passende Wahl von $U$ lässt sich dabei $\lambda$ als $\lambda = \sqrt{\tr(S^* S)/n}$ wählen, also als positiver reeller Skalar.
\end{remark}










\section{Lösungen zu Aufgabe 1}


Es sei $A \in \GL_n(\Rbb)$.





\subsection{}

Angenommen, es ist $A = \exp(B)$ für eine selbstadjungierte Matrix $B \in \Mat_n(\Rbb)$.
Da $B$ selbstadjungiert ist, gibt es nach Theorem~\ref{thrm: existence of unitary basis change matrix} eine orthogonale Basiswechselmatrix $O \in \Orthogonal(n)$, so dass $O B O^{-1} = \diag(\lambda_1, \dotsc, \lambda_n)$ mit $\lambda_1, \dotsc, \lambda_n \in \Rbb$.
Da $B$ selbstadjungiert ist, ist auch $A = \exp(B)$ selbstadjungiert, also symmetrisch.
Außerdem ist
\[
    O A O^{-1}
  = O \exp(B) O^{-1}
  = \exp(O B O^{-1})
  = \exp( \diag(\lambda_1, \dotsc, \lambda_n) )
  = \diag(e^{\lambda_1}, \dotsc, e^{\lambda_n})
\]
mit $\exp(\lambda_1), \dotsc, \exp(\lambda_n) > 0$.
Also sind alle Eigenwerte von $A$ positiv.

Angenommen, $A$ ist symmetrisch mit positiven Eigenwerten.
Da $A$ symmetrisch und reell ist, ist $A$ selbstadjungiert.
Da $A$ selbstadjungiert ist, gibt es nach Theorem~\ref{thrm: existence of unitary basis change matrix} eine orthogonale Basiswechselmatrix $O \in \Orthogonal(n)$, sodass $O A O^{-1} = \diag(\lambda_1, \dotsc, \lambda_n)$ mit \mbox{$\lambda_1, \dotsc, \lambda_n \in \Rbb$}.
Nach Annahme ist dabei $\lambda_1, \dotsc, \lambda_n > 0$.
Für $D \coloneqq \diag(\log(\lambda_1), \dotsc, \log(\lambda_n))$ ist
\[
    O A O^{-1}
  = \diag(\lambda_1, \dotsc, \lambda_n)
  = \exp(\diag(\log(\lambda_1), \dotsc, \log(\lambda_n)))
  = \exp(D),
\]
und somit $A = O^{-1} \exp(D) O = \exp(O^{-1} D O)$.
Da $D$ als reelle Diagonalmatrix selbstadjungiert ist und $O$ normal ist, ist nach Korollar~\ref{cor: properties and unitary basis change} auch $O^{-1} D O \in \Mat_n(\Rbb)$ selbstadjungiert.





\subsection{}

Angenommen, es ist $A = \exp(B)$ für antiselbstadjungiertes $B \in \Mat_n(\Rbb)$.
Da $B$ reell und antiselbstadjungiert ist, ist $\exp(A)$ reell und unitär, also orthogonal.
Da $B$ reell und antiselbstadjungiert ist, ist $B$ schiefsymmetrisch.
Deshalb sind sind alle Diagonaleinträge von $B$ Null, weshalb $\tr B = 0$ und deshalb $\det A = \det \exp(B) = \exp(\tr B) = \exp(0) = 1$.

Angenommen, $A$ ist orthogonal mit $\det A = 1$.
Da $A$ orthogonal ist, gibt es nach Theorem~\ref{thrm: existence of unitary basis change matrix} eine orthogonale Matrix $O \in \Orthogonal(n)$, so dass
\[
    O A O^{-1}
  = \block(1, \dotsc, 1, \underbrace{-1, \dotsc, -1}_{r}, D(\varphi_1), \dotsc, D(\varphi_r)),
\]
Die Vielfachheit $r$ des Einträges $-1$ muss gerade sein, da
\[
    1
  = \det A
  = \det(O A O^{-1})
  = 1 \dotsm 1
    \cdot \underbrace{(-1) \dotsm (-1)}_{r}
    \cdot \underbrace{\det D(\varphi_1)}_{=1} \dotsm \underbrace{\det D(\varphi_r)}_{=1}
  = (-1)^r
\]
Für $s = r/2$ ist deshalb
\[
    O A O^{-1}
  = \block(1, \dotsc, 1, \underbrace{-I, \dotsc, -I}_{s}, D(\varphi_1), \dotsc, D(\varphi_r)).
\]
Für die Matrix
\[
            B
  \coloneqq \block\Bigl(0, \dotsc, 0,
                        \underbrace{\frac{\pi}{2} J, \dotsc, \frac{\pi}{2} J}_{s},
                        \varphi_1 J, \dotsc, \varphi_r J
                  \Bigr)
\]
gilt nach Lemma~\ref{lem: finding a logarithm for rotation matrices}, dass $O A O^{-1} = \exp(B)$, und somit $A = O^{-1} \exp(B) O = \exp(O^{-1} B O)$.
Da $B$ antiselbstadjungiert ist (denn $J$ ist antiselbstadjungiert) und $O$ orthogonal ist, ist nach Korollar~\ref{cor: properties and unitary basis change} auch $O B O^{-1}$ antiselbstadjungiert.





\subsection{}

Angenommen, es ist $A = \exp(B)$ für normales $B \in \Mat_n(\Rbb)$.
Als normale Matrix ist $B$ über $\Cbb$ diagonalisierbar, d.h.\ es gibt $S \in \GL_n(\Cbb)$ mit $S B S^{-1} = \diag(\lambda_1, \dotsc, \lambda_n)$.
(Nach Theorem~\ref{thrm: existence of unitary basis change matrix} lässt sich $S$ orthogonal wählen, dies ist hier aber nicht nötig.)
Da $B$ eine reelle Matrix ist, ist für jeden nicht reellen Eigenwert $\lambda$ von $B$ auch $\overline{\lambda}$ ein Eigenwert von $B$, und $\lambda$ und $\overline{\lambda}$ haben die gleichen algebraischen (und geometrischen) Vielfachheiten.
Durch passende Wahl von $S$ ist deshalb o.B.d.A.
\[
    S B S^{-1}
  = \diag(\mu_1, \dotsc, \mu_r, \lambda_1, \overline{\lambda_1}, \dotsc, \lambda_s, \overline{\lambda_s})
\]
mit $\mu_1, \dotsc, \mu_r \in \Rbb$ und $\lambda_1, \dotsc, \lambda_s \in \Cbb$ nicht reell.
Daher ist
\[
    S A S^{-1}
  = S \exp(B) S^{-1}
  = \exp(S B S^{-1})
  = \diag(e^{\mu_1}, \dotsc, e^{\mu_r},
          e^{\lambda_1}, e^{\overline{\lambda_1}}, \dotsc, e^{\lambda_s}, e^{\overline{\lambda_s}}) .
\]
Die Eigenwerte $e^{\mu_1}, \dotsc, e^{\mu_r}$ von $A$ sind alle positiv.
Ist $\lambda$ ein negativer, reeller Eigenwert von $A$, so ist für alle $j = 1, \dotsc, s$ genau dann $\lambda = e^{\lambda_j}$, wenn $\lambda = \overline{e^{\lambda_j}} = e^{\overline{\lambda_j}}$.
Also ist $\lambda$ ein Eigenwert mit gerader Vielfachheit.

Angenommen, $A \in \Mat_n(\Rbb)$ ist normal und invertierbar, so dass alle negativen reellen Eigenwerte von $A$ gerade Vielfachheit haben.
Da $A$ reell und normal ist, gibt es nach Theorem~\ref{thrm: existence of unitary basis change matrix} eine orthogonale Matrix $O \in \Orthogonal(n)$ mit
\begin{align*}
      O A O^{-1}
  &=  \block( \lambda_1, \dotsc, \lambda_p,
              \mu_1, \mu_1, \dotsc, \mu_q, \mu_q,
              r_1 D(\varphi_1), \dotsc, r_s D(\varphi_s)  )   \\
  &=  \block( \lambda_1, \dotsc, \lambda_p,
              \mu_1 I, \dotsc, \mu_q I,
              r_1 D(\varphi_1), \dotsc, r_s D(\varphi_s)  ),  \\
  &=  \block( \lambda_1, \dotsc, \lambda_p,
              |\mu_1| (-I), \dotsc, |\mu_q| (-I),
              r_1 D(\varphi_1), \dotsc, r_s D(\varphi_s)  ),  \\
  &=  \block( \lambda_1, \dotsc, \lambda_p,
              |\mu_1| D(\pi), \dotsc, |\mu_q| D(\pi),
              r_1 D(\varphi_1), \dotsc, r_s D(\varphi_s)  ),
\end{align*}
wobei $\lambda_1, \dotsc, \lambda_p > 0$ die positiven reellen Eigenwerte von $A$ sind, $\mu_1, \dotsc, \mu_q < 0$ die negativen reellen Eigenwerte von $A$, $r_1, \dotsc, r_s > 0$ Radien und $\varphi_1, \dotsc, \varphi_s \in (0,\pi)$ Drehwinkel.
Für die Matrix
\begin{align*}
  B
  \coloneqq \block\Bigl(  \log(\lambda_1), \dotsc, \log(\lambda_p),
                         &\log(|\mu_1|) I + \pi J, \dotsc, \log(|\mu_q|) I + \pi J, \\
                         &\log(r_1) I + \varphi_1 J, \dotsc, \log(r_s) I + \varphi_s J                \Bigr)
\end{align*}
gilt nach Lemma~\ref{lem: finding a logarithm for rotation matrices}, dass $O A O^{-1} = \exp(B)$ und somit $A = O^{-1} \exp(B) O = \exp(O^{-1} B O)$.

Die Matrix $B$ ist normal:
Es ist
\begin{align*}
    B^*
  = B^T
  = \block\Bigl(  \log(\lambda_1), \dotsc, \log(\lambda_p),
                 &\log(|\mu_1|) I - \pi J, \dotsc, \log(|\mu_q|) I - \pi J, \\
                 & \log(r_1) I - \varphi_1 J, \dotsc, \log(r_s) I - \varphi_s J                \Bigr),
\end{align*}
und es genügt zu überprüfen, dass die einzelnen Blöcke von $B$ und $B^*$ jeweils miteinander kommutieren.

Für die $(1 \times 1)$-Blöcke $\log(\lambda_j)$ mit $j = 1, \dotsc, p$ ist dies klar.
Für die $(2 \times 2)$-Blöcke $\log(|\mu_j|) I + \pi J$ und $\log(|\mu_j|) I - \pi J$ mit $j = 1, \dotsc, q$, sowie auch für die die $(2 \times 2)$-Blöcke $\log(r_j) I + \varphi_j J$ und $\log(r_j) I - \varphi_j J$ mit $j = 1, \dotsc, s$ folgt dies daraus, dass $I$ und $J$ kommutieren.
Also kommutieren $B$ und $B^*$, weshalb $B$ normal ist.
Da $O$ orthogonal ist, ist nach Korollar~\ref{cor: properties and unitary basis change} damit auch $O^{-1} B O$ normal.






















\end{document}
